# -*- coding: utf-8 -*-
"""1. numpy linearRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wXwuRkGK8fH29hoSa5k9u_crhfFi06MN
"""

import numpy as np
import matplotlib.pyplot as plt

# Linear regression is essentially fitting the gradient and offset of the line eqn: y = mx + c
# We seek to minimise the error by generating a bets fit to the data...

# Nice guide a: https://glowingpython.blogspot.com/2012/03/linear-regression-with-numpy.html
# Nice guide b: https://machinelearningmastery.com/implement-simple-linear-regression-scratch-python

# So, ahem, borrowing some code/data

x = np.arange(0, 9)
y = [19, 20, 20.5, 21.5, 22, 23, 23, 25.5, 24]


# Algebra, see wikipedia: https://en.wikipedia.org/wiki/Simple_linear_regression
# (its a standard sln)
#
# m = sum((x(i) - mean(x)) * (y(i) - mean(y))) / sum( (x(i) - mean(x))^2 )
# c = mean(y) - m * mean(x)

def mean(lst):
    return np.mean(lst)


def sum(lst):
    return np.sum(lst)


def m(x, y):
    return sum((x - mean(y)) * (y - mean(y))) / sum(np.power(x - mean(x), 2))


def c(x, y, m_val):
    return mean(y) - (m_val * mean(x))


m_final = m(x, y)
c_final = c(x, y, m_final)

print(str(m_final) + " " + str(c_final))

_ = plt.plot(x, y, '-', np.arange(0, 9), m_final * np.arange(9) + c_final, '-')

# and: Lo we have a a shiny best fit line

# But... this isnt using a cost function or gradient descent.
